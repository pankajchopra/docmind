import spacy
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    get_response_synthesizer,
    QueryBundle,
)
from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.schema import Node, TextNode
from llama_index.core.graph_stores import SimpleGraphStore
from llama_index.core.indices.knowledge_graph.base import KnowledgeGraphIndex
from llama_index.llms.openai import OpenAI
from llama_index.core.node_parser import SimpleNodeParser
from llama_index.core import StorageContext, load_index_from_storage
from llama_index.core.retrievers import KGGraphRetriever
from llama_index.core.query_engine import KnowledgeGraphQueryEngine
from llama_index.core.postprocessor import KeywordExtractor
from llama_index.core.vector_stores import ChromaVectorStore
from chromadb.config import Settings
import chromadb
from typing import List, Tuple
import os

# ---------------------------- 1. Load and Chunk PDF Data using Langchain ----------------------------
# Ensure you have 'your_document.pdf' in the './data/' directory
loader = PyPDFLoader("./data/your_document.pdf")
langchain_documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=20)
chunks = text_splitter.split_documents(langchain_documents)

print(f"Loaded {len(langchain_documents)} pages.")
print(f"Split into {len(chunks)} chunks.")

# ---------------------------- 2. Extract Entities using SpaCy ----------------------------
nlp = spacy.load("en_core_web_sm")

def extract_entities(chunk: Document) -> list[str]:
    """Extracts named entities from a Langchain Document chunk."""
    doc = nlp(chunk.page_content)
    entities = [ent.text for ent in doc.ents]
    return entities

chunks_with_entities = []
for chunk in chunks:
    entities = extract_entities(chunk)
    chunks_with_entities.append({"chunk": chunk, "entities": entities})

print("\nExtracted entities from chunks.")

# ---------------------------- 3. Vectorize Chunks using Langchain Embeddings (via LlamaIndex) ----------------------------
embed_model = OpenAIEmbeddings()

# Convert Langchain Documents to LlamaIndex Nodes
nodes = [
    TextNode(text=chunk.page_content, metadata=chunk.metadata) for chunk in chunks
]

# ---------------------------- 4. Build a Knowledge Graph Index using LlamaIndex ----------------------------
# We'll use the entities to help build the graph
graph_store = SimpleGraphStore()
storage_context = StorageContext.from_defaults(graph_store=graph_store)

# We'll use the LLM to help identify relationships between entities and chunks
llm = OpenAI(model="gpt-3.5-turbo")  # Or any other suitable LLM

# Create a Knowledge Graph Index
kg_index = KnowledgeGraphIndex.from_documents(
    [Document(text=node.get_content(), metadata=node.metadata) for node in nodes],
    llm=llm,
    storage_context=storage_context,
    kg_triple_extract_template=(
        "You are a world-class entity extraction expert. Given the following text"
        " extract as many triplets as possible. A triplet consists of a subject, a"
        " predicate and an object. The subject and object must be named entities"
        " mentioned in the text. The predicate describes the relationship between"
        " the subject and the object. Follow the format 'SUBJECT -> PREDICATE ->"
        " OBJECT'.\n"
        "Text: {text}\n"
        "Triplets:"
    ),
)

print("\nKnowledge Graph Index created.")

# ---------------------------- 5. Create a Vector Store Index for Semantic Search ----------------------------
# Setup Chroma in-memory, for simplicity. For persistence, specify a persist_directory.
chroma_client = chromadb.Client(settings=Settings(allow_reset=True))
chroma_collection = chroma_client.get_or_create_collection("my_vector_store")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context_vector = StorageContext.from_defaults(vector_store=vector_store)
vector_index = VectorStoreIndex(nodes, storage_context=storage_context_vector, embed_model=embed_model)

print("Vector Store Index created.")

# ---------------------------- 6. Hybrid Search Retriever ----------------------------
class HybridGraphVectorRetriever(BaseRetriever):
    """
    A hybrid retriever that combines graph-based and vector-based retrieval.
    """

    def __init__(
        self,
        vector_retriever: VectorIndexRetriever,
        graph_retriever: KGGraphRetriever,
        vector_weight: float = 0.5,
        graph_weight: float = 0.5,
    ) -> None:
        self._vector_retriever = vector_retriever
        self._graph_retriever = graph_retriever
        self._vector_weight = vector_weight
        self._graph_weight = graph_weight

    def retrieve(self, query_bundle: QueryBundle) -> List[Node]:
        vector_nodes = self._vector_retriever.retrieve(query_bundle)
        graph_nodes = self._graph_retriever.retrieve(query_bundle)

        # Simple combination: weight the scores (if available) or just combine unique nodes
        combined_nodes = {}
        for node in vector_nodes:
            combined_nodes[node.node_id] = (combined_nodes.get(node.node_id, (0, node)) + (node.score or self._vector_weight, node))
        for node in graph_nodes:
            combined_nodes[node.node_id] = (combined_nodes.get(node.node_id, (0, node)) + (node.score or self._graph_weight, node))

        # Average the scores and sort
        averaged_nodes = sorted(
            [(score / 2, node) for score, node in combined_nodes.values()],
            key=lambda x: x[0],
            reverse=True,
        )
        return [node for _, node in averaged_nodes]

# Initialize the individual retrievers
vector_retriever = VectorIndexRetriever(index=vector_index)
graph_retriever = KGGraphRetriever(index=kg_index)

# Initialize the hybrid retriever
hybrid_retriever = HybridGraphVectorRetriever(
    vector_retriever=vector_retriever,
    graph_retriever=graph_retriever,
    vector_weight=0.6,  # Adjust weights as needed
    graph_weight=0.4,
)

# Create the hybrid query engine
hybrid_query_engine = RetrieverQueryEngine(
    retriever=hybrid_retriever,
    response_synthesizer=get_response_synthesizer(),
)

# ---------------------------- 7. Keyword Enhanced Vector Search ----------------------------
# Use a KeywordExtractor postprocessor to add relevant keywords to the query
keyword_extractor = KeywordExtractor(keywords_only=True, top_n=5)

def keyword_enhanced_vector_search(query: str, index: VectorStoreIndex, top_k: int = 10):
    """Performs vector search enhanced with keywords."""
    keywords = keyword_extractor.postprocess_nodes([TextNode(text=query)])[0].get_content()
    search_query = f"{query} {keywords}"
    retriever = VectorIndexRetriever(index=index, similarity_top_k=top_k)
    nodes_with_scores = retriever.retrieve(search_query)
    return nodes_with_scores

# ---------------------------- 8. Graph-Based Search ----------------------------
# Simple graph query engine
graph_query_engine = KnowledgeGraphQueryEngine(
    index=kg_index,
    llm=llm,
)

# ---------------------------- 9. Performing Queries ----------------------------
query_text = "Tell me about the main topics discussed in this document and any key entities."

print(f"\nQuery: {query_text}")

# Hybrid Search
hybrid_response = hybrid_query_engine.query(query_text)
print("\nHybrid Search Response:")
print(hybrid_response)

# Keyword Enhanced Vector Search
keyword_vector_results = keyword_enhanced_vector_search(query_text, vector_index, top_k=5)
print("\nKeyword Enhanced Vector Search Results:")
for node in keyword_vector_results:
    print(f"  Score: {node.score:.4f}, Content: {node.node.get_content()[:100]}...")

# Graph-Based Search
graph_response = graph_query_engine.query(query_text)
print("\nGraph-Based Search Response:")
print(graph_response)